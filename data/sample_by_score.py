import os
import argparse
import pandas as pd
import json
import numpy as np


def sample_by_score(parquet_file_path, score_file_path, score_field, num_samples,
                    mode="top", output_dir=None, print_only=True):
    """
    æ ¹æ® JSON æ–‡ä»¶é‡Œçš„åˆ†æ•°å­—æ®µç­›é€‰æ ·æœ¬ï¼Œå¹¶åœ¨ Parquet ä¸»æ•°æ®ä¸­æå–è¿™äº›æ ·æœ¬ä¿å­˜ï¼Œ
    åŒæ—¶æ‰“å°å‡º questionã€answer å’Œå¯¹åº”åˆ†æ•°ã€‚

    å‚æ•°:
        parquet_file_path: str, ä¸»æ•°æ® parquet æ–‡ä»¶
        score_file_path: str, JSON æ–‡ä»¶ï¼ˆåŒ…å« index å’Œå¯¹åº”åˆ†æ•°ï¼‰
        score_field: str, ç­›é€‰å­—æ®µ
        num_samples: int, æŠ½å–çš„æ ·æœ¬æ•°
        mode: str, "top" è¡¨ç¤ºå–æœ€é«˜çš„æ ·æœ¬ï¼Œ"bottom" è¡¨ç¤ºå–æœ€ä½çš„æ ·æœ¬
        output_dir: str, ä¿å­˜è·¯å¾„
        print_only: bool, å¦‚æœ True åªæ‰“å°ä¸ä¿å­˜ parquet
    """
    print(f"Loading main dataset from {parquet_file_path} ...")
    df = pd.read_parquet(parquet_file_path, engine="pyarrow")
    print(f"Total records in dataset: {len(df)}")

    print(f"Loading scores from {score_file_path} ...")
    with open(score_file_path, "r", encoding="utf-8") as f:
        scores = json.load(f)

    score_df = pd.DataFrame(scores)  # è½¬æˆ DataFrameï¼Œé‡Œé¢æœ‰ index å’Œå¯¹åº”åˆ†æ•°
    print(f"Loaded {len(score_df)} score records.")

    # å¦‚æœæ˜¯ hybridï¼Œåˆ™è®¡ç®—æ–°çš„å­—æ®µ
    if score_field == "hybrid":
        if not {"uncertainty_score", "reward_variance"}.issubset(score_df.columns):
            raise ValueError("è®¡ç®— hybrid_score éœ€è¦åŒæ—¶å­˜åœ¨ 'uncertainty_score' å’Œ 'reward_variance' å­—æ®µ")
        score_df["hybrid"] = score_df["uncertainty_score"] + np.sqrt(score_df["reward_variance"])

    if score_field not in score_df.columns:
        raise ValueError(f"Field '{score_field}' not found in score file. Available fields: {list(score_df.columns)}")

    # æŒ‰åˆ†æ•°æ’åº
    ascending = True if mode == "bottom" else False
    score_sorted = score_df.sort_values(by=score_field, ascending=ascending)

    # é€‰å‡ºç›®æ ‡ index
    num_samples = min(num_samples, len(score_sorted))
    selected_scores = score_sorted.head(num_samples)
    selected_indices = set(selected_scores["index"].tolist())

    # åœ¨ä¸»æ•°æ®ä¸­è¿‡æ»¤
    sampled_df = df[df["extra_info"].apply(lambda x: x["index"] in selected_indices)].copy()
    # æŠŠ extra_info["index"] æå–æˆä¸€åˆ—
    sampled_df["index"] = sampled_df["extra_info"].apply(lambda x: x["index"])

    # ğŸ”¹ æ‰“å° question, answer å’Œåˆ†æ•°
    print(f"\nğŸ“Š Top/Bottom {num_samples} samples by '{score_field}' ({mode}):\n")
    merged = sampled_df.merge(selected_scores, on="index")
    for _, row in merged.iterrows():
        question = row["prompt"][0]["content"]
        answer = row["reward_model"]["ground_truth"]
        score = row[score_field]
        print(f"Index={row['extra_info']['index']} | Score={score:.4f}")
        print(f"Q: {question}")
        print(f"A: {answer}\n{'-'*80}")

    # ğŸ”¹ å¦‚æœä¸æ˜¯ print_onlyï¼Œåˆ™ä¿å­˜ parquet
    if not print_only:
        if output_dir is None:
            output_dir = os.path.dirname(parquet_file_path)
        os.makedirs(output_dir, exist_ok=True)

        base_name = os.path.splitext(os.path.basename(parquet_file_path))[0]
        output_file = os.path.join(output_dir, f"{base_name}_{score_field}_{mode}{num_samples}.parquet")

        sampled_df.to_parquet(output_file, engine="pyarrow", index=False)
        print(f"\nâœ… Saved sampled dataset to {output_file}")

    return sampled_df


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Sample data from a parquet file by external score JSON")
    parser.add_argument("--input", type=str, required=True, help="Path to input parquet file (main data)")
    parser.add_argument("--score_file", type=str, required=True, help="Path to JSON file containing scores")
    parser.add_argument("--field", type=str, required=True,
                        choices=["uncertainty_score", "reward_variance", "hybrid", "ifd", "ppl", "score", "token_length"],
                        help="Field name to sort and select samples")
    parser.add_argument("--num", type=int, required=True, help="Number of samples to select")
    parser.add_argument("--mode", type=str, choices=["top", "bottom"], default="top",
                        help="Select top or bottom samples (default: top)")
    parser.add_argument("--output_dir", type=str, default=None,
                        help="Directory to save output parquet file (default: same as input)")
    parser.add_argument("--print_only", action="store_true", help="Only print results without saving parquet")

    args = parser.parse_args()
    sample_by_score(args.input, args.score_file, args.field, args.num,
                    args.mode, args.output_dir, print_only=args.print_only)
